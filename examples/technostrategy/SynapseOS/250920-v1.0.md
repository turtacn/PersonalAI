# XOS洞察规划汇总

1）融合平台历史债&质量改进部分（+责任田）  

| 模块 | xos 债务 | ske 债务 | 融合效果 |
| --- | --- | --- | --- |
| 打包与CI/CD | 【能力欠缺】<br>·制品类型单一，无VMA/ISO，无法支撑全场景交付，增加了产线适配工作量，且不利于新产线业务快速验证。<br>·有的镜像直接拉去的开源镜像，源码未归档，Patch管理混乱，审计溯源困难，存在安全风险。<br>【性能与流程】<br>·构建流程冗长，存在大量非核心的制品制作过程，效率低下。<br>·手动干预环节多，模块打包相互依赖易出错，不符合DevOps最佳实践。<br>·并发打包易冲突 | 【架构依赖】<br>·强依赖Bello构建平台，与内部DevOps流程（千流）割裂。<br>【效率与体验】<br>·产线复用方式原始（Fork仓库），未做成多XaaS化，不利于大规模协作。<br>·大型制品（VMA、ISO、PKG、）过大，传输、存储成本高。 | 1. 构建“构建即服务”的统一云原生构建平台<br> 多节式构建引擎：平台内置强大的构建引擎，必须同时具备持续集成流水线调度能力（类似千流）和复杂制品构建管理能力（类似Bello）。<br> 多节式构建支持：统一支持系统镜像（ISO）、虚拟机镜像（VMA）及软件包（Pkg）的构建，满足从云原生应用到传统应用的全场景交付需求。<br>2. 智能优化与加速<br> 分层与裁剪：采用智能分层技术，基于Alpine等极小化基础镜像，并结合业务特性裁剪非必要组件，目标降低制品体积>10%。<br> 并发构建与缓存：引入分布式并发构建机制和全局缓存，显著缩短构建时长，目标提升效率>20%。<br>3. 资产治理与安全<br> 实现源码、构建环境、制品的全链路关联与归档，具备完整的SBOM（软件物料清单）能力，为安全审计、漏洞扫描和精准Patch提供坚实基础。 |
| 安装部署 | NA | 【扩展性与体验】<br>·架构设计未充分考虑多业务模块的灵活集成，扩展性不足。<br>·裸金属部署依赖大量后台手动配置，体验差，易出错，影响交付效果。<br>·安装时长较长，影响业务上线速度。 | 1. 开箱即用：一键部署，提升易用性，减少裸金属手动配置。<br>2. 安装效率：优化安装流程和依赖检查，缩短安装时长。<br>3. 扩展性设计：在架构中预留业务集成接口，保证未来扩展能力，提升安装部署复用能力。<br>4. 代码统一：将SKE/XOS的安装代码合一到融合平台，提升整体可维护性和一致性，减少维护成本。 |
| 升级 | 【能力欠缺】<br>·不支持k8s升级,导致无法快速使用新特性,存在潜在的安全漏洞风险<br>·升级框架不具备自我升级能力,存在升级过程繁琐易错,依赖人工,服务中断风险高,回滚困难的问题。<br>·跨版本升级能力不足,升级路径漫长,运维成本激增,影响业务中断时间; | 【架构与体验】<br>·升级框架与业务逻辑耦合深,变得沉重且不灵活。<br>·升级包巨大,上传时间长,升级窗口长,业务影响风险高。<br>·缺乏前置健康巡检,升级稳定性保障不足。 | 1. 解耦与通用化：剥离升级框架与业务特性的强绑定依赖，构建轻量级通用升级体系。<br>过架构层面的去业务化设计,最大化提升框架的可扩展性与跨场景复用能力,轻松适配不同业务形态的升级需求。<br>2. 能力补齐：聚焦全系升级场景的核心能力补全、按需覆盖三大关键场景——K8s环境专属升级、跨版本平滑过渡升级、框架自身迭代升级,形成“无短板、全场景”的升级能力矩阵,确保各类升级需求均能高效落地。<br>3. 体验优化：<br>·采用增量升级包技术,仅包含版本间差异内容,大幅缩减升级包体积,降低传输带宽与存储资源消耗。<br>·引入“升级前自动巡检+升级后效果验证”双机制:前置巡检提前排查环境风险,后置验证确保升级效果达标,既强化了升级稳定性、降低操作门槛,又有效缩短整体升级耗时,提升用户操作体验。 |
| 集群管理 | 【能力与架构】<br>·高可用方案不完整(如无2节点HA),故障自愈能力弱。<br>·集群生命周期管理场景缺失(如节点替换)。<br>·部署与配置耦合,可维护性差。<br>·缺乏安全的节点删除/移除能力,无法完成完整的缩容或节点下线操作。 | 【架构局限性】<br>·初始设计为单节点,缺乏大规模集群管理经验,无高可用能力,可靠性差。 | 构建“企业级PRO版”的全生命周期集群管理<br>1. 高可用架构增强: 借鉴XOS的集群管理基础,提供从两节点主备到多节点多活的灵活高可用方案,满足不同等级的RTO/RPO要求。<br>2. 自治与自愈能力: 实现完整的集群生命周期自动化管理,包括:<br>·自动扩缩容:基于预定义策略或实时负载进行弹性伸缩<br>·故障节点自动隔离与替换:节点故障后自动迁移Pod并引入新节点,实现“自愈”。<br>·单节点恢复出厂:快速重置异常节点,提升运维效率。<br>3. 安全的节点删除与自动化工作负载迁移:<br>·安全删除流程:提供“节点排空”功能,在删除节点前、自动、优雅地将其上的Pod驱逐至集群内其他健康节点,确保业务零中断。 |
| 节点管理 | 【设计问题】<br>节点管理能力分布到多个进程中,不利于功能复用。 | 【能力欠缺】<br>裸金属节点管理比较零散 | 1. 统一节点管理:以XOS-agent为蓝本,构建融合平台的统一节点管理能力,支持xos平台和ske平台,提升组件的复用率,减少多个产品的维护成本。<br>2. 能力拓展:补齐对裸金属节点的磁盘、电源等硬件管理能力,提升交付运维效率。 |
| 网络 | 【设计问题】· 网口IP地址变更时间长· 代码可读性差,代码冗余多<br>【能力欠缺】· 缺乏现代网络功能(IPV6、主机防火墙、聚合口等)· 多CNI能力由产线实现,增加了产线负担<br>【可靠性、易用性】网络策略与底层基础设施联动差,存在安全风险。· 不支持聚合口能力以及网卡速率显示· 不支持批量删除路由和dns· 云主机后台修改ip可能导致集群异常 | 【易用性】<br>· 高级网络功能重后台CLI操作,对普通用户不好。 | 1. 统一管理模块:统一主机网关管理模块,提供前端图形化配置,替代后台手动操作,减少功能维护成本,提升交付运维效率,提升交付满意度。<br>2. 功能增强:· 实现IPV6能力以及防火墙等安全套件可配置,增强集群安全能力。· 支持聚合口、网卡速率显示、批量删除路由/DNS等高级功能,提升可靠性和易用性。<br>3. 性能与稳定:优化底层代码,减少冗余,降低网络配置变更时长,防止后台操作引发集群异常。<br>4. 多CNI内置:在平台层面集成多CNI能力,减轻产线适配维护的负担。 |
| 存储管理 | 【架构缺陷】<br>· 存储管理强耦合于K8sOperator,架构不合理,存在隐式风险。 | 【易用性】<br>· 配置不够直观(后台),裸金属体验差。 | 1. 架构解耦:重新设计存储管理模块,实现与K8s解耦,降低隐式风险,提升可靠性。<br>2. 统一体验:提供统一的前端配置界面,简化裸金属和虚拟化环境的存储管理。 |
| K&S | 【轻量】· docker资源开销大、调用链长,暴露面广<br>【性能】· 调度性能差,无法满足大数据等业务的调度需求 | 【资源】· SKE底座当前4C8G,资源成本高 | 1. 极致轻量化:深度融合XOS的轻量基因,对K8s控制面组件进行深度优化和资源限制。目标将默认底座资源要求降低至1C4G,大幅降低用户TCO。<br>2. 高性能调度:实现100Pods/秒的调度性能,满足敏捷开发和弹性伸缩的极致需求。<br>3. 智能运维与资源效率:· 建立Pod资源使用画像和性能基线,为HPA/VPA提供精准依据,实现业务动态扩缩容能力。· 优化镜像拉取、容器启动及资源回收流程,实现Pod内存占用降低50%,提升整体资源利用率。· 提供强大的多租户能力、配额管理与资源隔离能力,满足大数据等产线对多租户能 |


# 2）参与版本价值&产线支撑

# (1.0) 版本价值：

# 【资源降本】

底座深度优化：通过架构轻量化与资源精细化管控，实现平台底座资源占用显著降低，满足产品（如VDC）等严苛资源成本要求，直接为产线降低基础设施成本。

# 【业务增效】

交付效率倍增：提供端到端一键式的安装、升级与运维体验，极大简化流程，提升产线交付与客户实施效率。

加速业务孵化：提供线上线下一体化的通用平台架构与能力，大幅缩短新业务从开发到上市的周期。

支撑全球拓展：内置国际化框架与多地域部署能力，支撑产线产品实现快速的国际化交付，抢占全球市场。

# 【质量&稳定】

性能隔离保障：通过资源隔离与 QoS 机制，确保在多业务混部场景下，核心应用的性能与稳定性不受干扰。

开箱即用的可靠性：提供集成的、经过验证的底座与中间件解决方案，降低技术复杂度，提升平台整体稳定性与安全性。

技术持续领先：通过升级K8s基础组件与引入动态资源分配（DRA）、异步调度等新特性，持续提升平台性能与稳定性，构筑产线业务的长期技术竞争力。

# 【多产品融合】

产品快速组合：通过虚拟集群技术，实现灵活的多产品组合与隔离，支持多样化的产品形态与销售策略，提升市场竞争力。

强大的多租户支持：满足大数据等业务场景对强隔离、多租户能力的核心诉求，助力业务拓展。

# 【统一公司平台底座】

统一平台底座：通过融合SKE与XaaSOS的公共能力，打造公司级统一的XaaS平台底座，为多产线、多业务提供标准化的中间件与一体化解决方案。

标准化交付方案：针对SaaS场景，形成“标准化XaaSOS底座+中间件”的成熟交付方案，提升交付质量与效率。

支撑业务演进：为公司的成熟业务持续演进和新业务快速孵化，提供统一、稳定、可扩展的技术支撑。

产品支撑：  

---

好的，这就为您处理。

首先，根据原文内容，识别出的产品名称共 5 个：

* 安全数据大脑
* VDC (预计2025年11月份立项)
* 容灾 (预计2026年1月立项)
* AIPAAS (已立项)
* AICP-2.4.0 (已立项)

接下来，我将按照您的要求，为每个产品生成一份独立的、符合规范的 Markdown 文本。

---

# 安全数据大脑

### 支撑价值

平台建设旨在解决大数据与 AI 场景下的资源隔离、调度效率、资源利用率及运维管理等核心挑战。其价值体现在：

* 解决 **多租户共享集群时，资源分配、成本核算与故障隔离难** 的问题，或满足 **保障关键业务资源、避免租户间“资源争抢”** 的原始需求，最终达成 **在共享集群上实现强制的资源隔离与灵活的配额管理** 的效果。
* 解决 **海量大数据离线作业瞬时并发导致调度瓶颈与延迟** 的问题，或满足 **高并发、大规模任务的高效处理** 的原始需求，最终达成 **显著提升业务处理效率与集群资源利用率** 的效果。
* 解决 **Pod 创建过程中镜像拉取耗时长、终止后资源回收不及时** 的问题，或满足 **计算资源快速轮转、提升任务吞吐量** 的原始需求，最终达成 **加速 Pod 生命周期、提升整体资源周转效率** 的效果。
* 解决 **Hadoop、Spark 等大数据组件部署流程繁琐、缺乏统一运维视图** 的问题，或满足 **对多类型大数据组件进行集中化、白屏化管控** 的原始需求，最终达成 **简化部署与运维、降低管理复杂度** 的效果。
* 解决 **任务容器日志分散、易丢失且查询效率低** 的问题，或满足 **故障诊断、审计和作业复盘时对历史日志的可靠追溯** 的原始需求，最终达成 **任务日志的持久化收集、归档与快速检索** 的效果。

---

### 平台能力需求

#### 能力-1: 多租户资源隔离与配额管理

| 技术手段                                             | 解决的问题                             | 达成的效果                              | 优先级 | 支持情况     | 预计交付时间   |
| :----------------------------------------------- | :-------------------------------- | :--------------------------------- | :--- | :------- | :------- |
| 基于 Kubernetes Namespace 的资源配额（Requests/Limits）管理 | 如何在共享集群中为不同租户分配和限制基础计算资源。         | 为每个部门或租户分配独立的资源配额，实现基础的计算资源隔离。     | 高   | 不支持租户级能力 | 5-8 人天   |
| 集成 Volcano 等批调度器实现队列调度                           | 如何保障高优先级租户的任务总能获得所需资源，避免资源饿死。     | 支持按资源队列调度，允许关键部门抢占非关键任务资源，满足高峰期需求。 | 高   | 不支持      | 10-15 人天 |
| 基于 vCluster 技术的虚拟集群隔离                            | 如何为特定租户提供控制平面级别的强隔离，满足最高安全与独立性要求。 | 提供逻辑上完全独立的 K8s 控制平面，隔绝所有级别的操作干扰。   | 高   | 不支持      | 15-20 人天 |
| 提供动态资源配额调整的 API 或管理界面                            | 如何灵活、动态地调整各租户的资源配额以应对业务变化。        | 支持动态调整各隔离域的 CPU、内存、GPU 等计算资源配额上限。  | 高   | 不支持      | 8-10 人天  |

---

#### 能力-2: 高性能大规模任务调度

| 技术手段                    | 解决的问题                               | 达成的效果                              | 优先级 | 支持情况 | 预计交付时间   |
| :---------------------- | :---------------------------------- | :--------------------------------- | :--- | :--- | :------- |
| 优化调度器吞吐量，实现稳定高 Pod 创建速率 | 标准 Kubernetes 调度器在海量作业并发创建时出现的性能瓶颈。 | 在标准测试集群中，实现不低于 100 Pods/秒的稳定调度吞吐量。 | 高   | 不支持  | 15-20 人天 |
| 调度器算法并发优化               | 大批量 Pod 调度时，串行的预选和优选流程导致的调度延迟。      | 对批量创建的 Pod 进行并发预选和优选，极大减少调度循环耗时。   | 高   | 不支持  | 10-15 人天 |

---

#### 能力-3: Pod 生命周期快速管理

| 技术手段                  | 解决的问题                              | 达成的效果                                  | 优先级 | 支持情况 | 预计交付时间   |
| :-------------------- | :--------------------------------- | :------------------------------------- | :--- | :--- | :------- |
| 实施节点级的镜像预热策略          | Pod 首次启动时因需从仓库拉取镜像而导致的启动延迟。        | 将常用基础镜像预先拉取到指定节点组，消除 Pod 启动时的镜像下载延迟。   | 高   | 支持   | 3-5 人天   |
| 容器运行时（Containerd）深度调优 | 容器环境自身的初始化与启动过程存在优化空间，影响 Pod 启动速度。 | 对于已预热镜像的 Pod，实现亚秒级（<500ms）的启动速度。       | 高   | 不支持  | 10-15 人天 |
| 强化 Pod 垃圾回收（GC）机制     | Pod 终止后，其占用的计算、网络等资源未能被系统快速释放。     | 确保 Pod 终止后，其占用的计算资源与网络 IP 等在1分钟内被快速回收。 | 高   | 不支持  | 8-12 人天  |

---

#### 能力-4: 大数据组件统一生命周期管理

| 技术手段                             | 解决的问题                              | 达成的效果                                      | 优先级 | 支持情况 | 预计交付时间   |
| :------------------------------- | :--------------------------------- | :----------------------------------------- | :--- | :--- | :------- |
| 构建基于 Helm Chart 或 Operator 的组件市场 | 大数据组件部署过程复杂、易出错，且缺乏标准化。            | 提供常用大数据组件的应用市场，支持参数化的一键部署、配置与版本管理。         | 中   | 不支持  | 15-20 人天 |
| 提供面向大数据组件的统一运维管理界面               | 缺乏对已部署组件进行健康检查、扩缩容、配置变更等日常运维的集中管理。 | 提供白屏化操作界面，集成健康检查、监控告警、日志、配置、升级、扩缩容等全套运维能力。 | 中   | 支持   | 10-15 人天 |
| 构建大数据组件专属的监控大盘                   | 通用监控指标无法深入反映大数据组件（如 JVM）的内部运行状态。   | 提供组件级别的专属监控大盘，关注 JVM 内存、GC、作业状态等大数据特定指标。   | 中   | 支持   | 5-8 人天   |

---

#### 能力-5: 任务日志持久化与检索

| 技术手段                              | 解决的问题                          | 达成的效果                                | 优先级 | 支持情况 | 预计交付时间   |
| :-------------------------------- | :----------------------------- | :----------------------------------- | :--- | :--- | :------- |
| 通过 DaemonSet 部署节点级日志采集代理          | 业务容器日志分散在各节点，需业务方自行改造才能实现集中收集。 | 自动采集所有节点的容器标准输出和指定路径的日志文件，对业务应用透明。   | 中   | 支持   | 3-5 人天   |
| 集成 Elasticsearch 或 Loki 日志存储与检索引擎 | 海量日志存储后的查询效率低下，难以满足快速故障定位的需求。  | 提供基于任务 ID、时间戳等多维度的快速检索，千万级日志查询响应<5秒。 | 中   | 不支持  | 10-15 人天 |
| 制定并执行日志生命周期管理策略                   | 日志数据长期存储导致成本高昂，且缺乏自动归档或清理机制。   | 支持配置日志保留策略，过期日志可自动归档至对象存储或进行清理。      | 中   | 不支持  | 5-8 人天   |

---

# VDC (预计2025年11月份立项)

### 支撑价值

平台建设旨在解决大规模用户并发场景下的集群稳定性、故障自愈、负载均衡及容灾等核心问题。其价值体现在：

* 解决 **大规模集群交付复杂、性能指标不明确** 的问题，或满足 **支撑5万用户并发访问** 的原始需求，最终达成 **标准化、可预期的集群交付与性能保障** 的效果。
* 解决 **节点硬件、网络或操作系统故障导致业务中断** 的问题，或满足 **故障自动检测与业务快速恢复** 的原始需求，最终达成 **分钟级的故障发现与自愈能力** 的效果。
* 解决 **请求被调度到亚健康节点导致服务质量下降** 的问题，或满足 **流量动态规避潜在故障节点** 的原始需求，最终达成 **基于节点健康度的智能、平滑的流量调度** 的效果。
* 解决 **服务实例的流量分发不均** 的问题，或满足 **所有接入服务自动实现负载均衡** 的原始需求，最终达成 **业务负载在各健康节点上的均匀分配** 的效果。
* 解决 **系统整体超压时产生雪崩效应、完全瘫痪** 的问题，或满足 **极端负载下保证核心服务可用性** 的原始需求，最终达成 **通过网关有序拒绝请求，避免系统整体崩溃** 的效果。
* 解决 **单数据中心故障导致业务整体不可用** 的问题，或满足 **RPO=12h, RTO=30min 的站点级容灾** 的原始需求，最终达成 **通过冷备站点切换实现业务的快速恢复** 的效果。
* 解决 **运维排障时信息分散、操作繁琐** 的问题，或满足 **简化运维、提升问题定位效率** 的原始需求，最终达成 **基础设施监控数据开放与日志一键收集** 的效果。
* 解决 **小规模客户场景下资源成本高、部署复杂** 的问题，或满足 **在 1-2 台虚拟机中实现高可用部署** 的原始需求，最终达成 **提供轻量化、高可用的合一部署模式** 的效果。
* 解决 **组件或底座升级窗口长、影响业务迭代速度** 的问题，或满足 **快速交付客户价值、缩短升级窗口** 的原始需求，最终达成 **组件独立、平滑的升级能力** 的效果。

---

### 平台能力需求

#### 能力-1: 大规模并发支持能力

| 技术手段            | 解决的问题                        | 达成的效果                                     | 优先级 | 支持情况 | 预计交付时间   |
| :-------------- | :--------------------------- | :---------------------------------------- | :--- | :--- | :------- |
| 提供标准化的自动化集群部署模板 | 手动部署大规模集群流程复杂、易出错，且缺乏最佳实践。   | 提供经充分验证的自动化部署蓝图，集成网络、存储等最佳实践，实现快速可靠的集群交付。 | 中   | 不支持  | 10-15 人天 |
| 内置性能测试套件与容量监控告警 | 如何验证集群是否满足预期并发目标，以及如何进行容量规划。 | 可对集群进行压力测试以验证其性能，并通过资源水位监控告警为容量规划提供数据支撑。  | 中   | 不支持  | 8-12 人天  |

---

#### 能力-2: 自动化节点故障自愈

| 技术手段                 | 解决的问题                                  | 达成的效果                                 | 优先级 | 支持情况 | 预计交付时间   |
| :------------------- | :------------------------------------- | :------------------------------------ | :--- | :--- | :------- |
| 实施覆盖硬件、系统、网络的多维度健康检测 | 如何实时、全面地发现节点的各类系统级故障（如硬件错误、网络丢包、系统假死）。 | 通过 Agent 和探针持续监测节点的硬件、系统及网络健康度。       | 中   | 部分支持 | 10-15 人天 |
| 构建自动化的故障决策与隔离、恢复执行逻辑 | 发现节点故障后，如何自动进行处置以恢复业务，而非依赖人工干预。        | 实现 1 分钟内发现故障，并通过节点隔离等手段在 5 分钟内自动恢复业务。 | 中   | 不支持  | 15-20 人天 |
| 提供故障事件的全过程可观测性视图     | 故障发生及自愈后，缺乏对整个事件过程的记录，不利于审计与复盘。        | 提供完整的故障事件时间线视图，记录从检测、决策到恢复的全过程。       | 中   | 不支持  | 5-8 人天   |

---

#### 能力-3: 基于健康度的智能调度

| 技术手段                 | 解决的问题                                   | 达成的效果                                      | 优先级 | 支持情况 | 预计交付时间   |
| :------------------- | :-------------------------------------- | :----------------------------------------- | :--- | :--- | :------- |
| 构建节点健康度实时评分模型        | 调度器无法感知节点的实时“健康”状态（如高负载），可能将请求分发至亚健康节点。 | 构建一个综合 CPU 负载、内存压力、网络 I/O 等指标的节点健康度实时评分模型。 | 中   | 不支持  | 12-18 人天 |
| 调度器与健康度评分模型联动，动态调整权重 | 如何根据节点的健康状况，智能地引导新请求的流量分配。              | 当节点健康分低于阈值时，调度器动态降低其权重，使新请求平滑地流向更健康的节点。    | 中   | 不支持  | 8-12 人天  |
| 设计平滑的流量迁移策略以避免“惊群效应” | 权重调整过于剧烈可能导致流量在节点间剧烈震荡，影响业务稳定性。         | 确保调度策略平滑，避免流量在节点间剧烈波动，保障业务平稳运行。            | 中   | 不支持  | 5-8 人天   |

---

#### 能力-4: 接入层能力

| 技术手段                                 | 解决的问题                                                    | 达成的效果                                                     | 优先级 | 支持情况 | 预计交付时间  |
| :----------------------------------- | :------------------------------------------------------- | :-------------------------------------------------------- | :--- | :--- | :------ |
| 集成 MetalLB 等负载均衡方案                   | 如何为 Kubernetes 中的服务（Service）提供统一、自动化的 LoadBalancer 类型支持。 | 自动化管理 LoadBalancer 类型的 Service，为每个对外服务分配稳定的 VIP，实现流量均匀分发。 | 中   | 支持   | 5-8 人天  |
| 基于 SKE APISTX 构建 Ingress 网关并配置全局限流策略 | 当系统整体负载过高时，如何避免所有服务同时过载，导致系统雪崩。                          | 提供全局限流、熔断等高级策略。当整体负载超水位时，网关自动有序拒绝请求，保护系统。                 | 中   | 支持   | 8-12 人天 |

---

#### 能力-5: 站点级容灾（冷备）

| 技术手段                | 解决的问题                          | 达成的效果                                  | 优先级 | 支持情况 | 预计交付时间   |
| :------------------ | :----------------------------- | :------------------------------------- | :--- | :--- | :------- |
| 提供图形化的主备站点管理与一键切换能力 | 跨站点容灾的配置、管理和切换演练流程复杂，依赖人工操作。   | 提供图形化界面管理主备站点关系，支持站点间配置和一键切换演练。        | 中   | 不支持  | 15-20 人天 |
| 构建跨数据中心的数据同步协调与监控机制 | 如何确保主备站点间底层中间件（数据库、缓存等）的数据一致性。 | 平台负责协调底层 PaaS 中间件启动跨数据中心同步，并监控同步状态和延迟。 | 中   | 支持   | 10-15 人天 |

---

#### 能力-6: 平台运维支撑

| 技术手段                 | 解决的问题                               | 达成的效果                                   | 优先级 | 支持情况 | 预计交付时间 |
| :------------------- | :---------------------------------- | :-------------------------------------- | :--- | :--- | :----- |
| 提供标准 API 开放基础设施层监控指标 | 业务监控系统难以获取底层基础设施（I/O、内存、节点状态）的详细指标。 | 稳定采集基础设施层指标，并通过标准 API 开放给业务监控系统，实现职责分离。 | 中   | 支持   | 5-8 人天 |
| 提供一键式日志收集与打包下载工具     | 在故障排查时，手动收集分布在多台机器上的相关日志费时费力。       | 可一键收集指定时间段、指定服务的所有相关日志并打包下载，简化运维操作。     | 中   | 支持   | 3-5 人天 |

---

#### 能力-7: 部署与升级

| 技术手段               | 解决的问题                                 | 达成的效果                           | 优先级 | 支持情况 | 预计交付时间  |
| :----------------- | :------------------------------------ | :------------------------------ | :--- | :--- | :------ |
| 提供优化的两节点集群自动化部署方案  | 如何在资源有限的小规模场景（如 1-2 台虚拟机）中实现平台的高可用部署。 | 提供轻量化、高可用的两节点集群自动化部署方案。         | 中   | 不支持  | 8-12 人天 |
| 设计支持灰度发布的组件独立升级流水线 | 平台作为一个整体进行升级，导致升级窗口长，无法满足单个组件的快速迭代需求。 | 确保单个组件的升级不影响平台其他服务，实现平滑演进和快速交付。 | 中   | 已支持  | -       |
| 提供平滑的底座升级能力        | 如何将旧版本的平台底座升级到新版本。                    | 实现平台底座的平滑升级。                    | 中   | 已支持  | -       |
| 支持时区与夏令时配置         | 平台缺乏对时区和夏令时的统一配置管理。                   | 支持对系统时区及夏令时进行修改。                | 中   | 不支持  | 2-3 人天  |

---

# 容灾 (预计2026年1月立项)

### 支撑价值

平台建设旨在提供一个标准化的、高可用的、可观测且易于管理的灾备系统。其价值体现在：

* 解决 **灾备系统部署复杂、配置易错** 的问题，或满足 **开箱即用、快速交付** 的原始需求，最终达成 **通过标准化安装包实现一键化部署** 的效果。
* 解决 **系统各部分（组件、K8s、平台自身）升级流程不统一、管理困难** 的问题，或满足 **对整个灾备系统进行统一、高效的升级管理** 的原始需求，最终达成 **提供全栈统一的升级管理能力** 的效果。
* 解决 **灾备系统控制面单点故障导致整个系统不可用** 的问题，或满足 **灾备系统自身的高可用性** 的原始需求，最终达成 **核心组件集群化部署，实现负载均衡和故障自动转移** 的效果。
* 解决 **故障排查时日志信息不全、定位效率低** 的问题，或满足 **为技术支持和运维提供最全面的现场信息** 的原始需求，最终达成 **一键打包下载完整的服务与操作日志，缩短故障排查时间** 的效果。
* 解决 **对 Kubernetes 自定义资源（CR）的生命周期变更缺乏端到端的可视性** 的问题，或满足 **跨系统的请求链路追踪与可视化** 的原始需求，最终达成 **实现对 CR 全生命周期事件的链路跟踪** 的效果。
* 解决 **监控告警能力固化、难以适应复杂业务场景** 的问题，或满足 **灵活自定义告警规则、并与外部系统无缝对接** 的原始需求，最终达成 **构建一个支持代码级自定义逻辑的可扩展监控告警框架** 的效果。
* 解决 **缺乏对不同租户的资源使用限制和操作权限控制** 的问题，或满足 **多租户环境下的资源隔离与安全授权** 的原始需求，最终达成 **实现基于命名空间的资源配额与基于角色的细粒度权限控制** 的效果。
* 解决 **跨站点数据同步依赖底层组件、平台层缺乏统一协调与监控** 的问题，或满足 **平台提供统一的数据同步协调能力** 的原始需求，最终达成 **由平台负责协调和监控跨数据中心的数据同步通道** 的效果。
* 解决 **基础设施网络配置单一，无法满足多网络平面隔离的需求** 的问题，或满足 **支持为节点配置多网卡并应用独立路由策略** 的原始需求，最终达成 **支持在基础设施层面进行多网络平面的高级网络配置** 的效果。
* 解决 **基础网关功能不足，缺乏企业级的流量治理能力** 的问题，或满足 **对 API 流量进行认证、限流、熔断等高级管控** 的原始需求，最终达成 **提供一个插件生态丰富、可声明式管理的 API 网关** 的效果。

---

### 平台能力需求

#### 能力-1: 标准化交付与运维

| 技术手段                       | 解决的问题                             | 达成的效果                            | 优先级 | 支持情况 | 预计交付时间   |
| :------------------------- | :-------------------------------- | :------------------------------- | :--- | :--- | :------- |
| 提供 VMA 虚拟机镜像和 ISO 两种标准化安装包 | 如何简化灾备系统的初始部署流程，降低实施门槛。           | 内置最佳实践配置，实现开箱即用的一键化部署。           | 低   | 支持   | 5-8 人天   |
| 构建全栈统一的升级管理引擎              | 如何统一管理组件、Kubernetes 内核、平台自身的版本升级。 | 实现对整个灾备系统的统一升级管理。                | 低   | 支持   | 10-15 人天 |
| 提供一键式日志打包下载功能              | 如何在技术支持场景下，快速、完整地收集现场的所有相关日志。     | 一键打包下载完整的服务与操作日志，为故障排查提供全面的信息输入。 | 低   | 支持   | 3-5 人天   |

---

#### 能力-2: 平台高可用与可观测性

| 技术手段                      | 解决的问题                              | 达成的效果                                    | 优先级 | 支持情况 | 预计交付时间   |
| :------------------------ | :--------------------------------- | :--------------------------------------- | :--- | :--- | :------- |
| 将系统核心控制面组件进行微服务化和集群化部署    | 如何避免灾备系统自身的控制面出现单点故障。              | 实现核心组件的负载均衡和故障自动转移，保障平台自身高可用。            | 低   | 支持   | 15-20 人天 |
| 集成链路追踪能力，支持对 CR 生命周期事件的追踪 | 复杂业务流程中，难以追踪一个自定义资源（CR）从创建到删除的全过程。 | 支持对 CR 的创建、更新、删除等生命周期事件进行跟踪，并可视化跨系统请求链路。 | 低   | 不支持  | 15-20 人天 |

---

#### 能力-3: 可扩展的监控、配额与授权

| 技术手段                     | 解决的问题                             | 达成的效果                              | 优先级 | 支持情况 | 预计交付时间   |
| :----------------------- | :-------------------------------- | :--------------------------------- | :--- | :--- | :------- |
| 提供支持 API 和代码逻辑自定义的告警框架   | 内置的告警规则无法满足所有复杂的、定制化的业务监控需求。      | 支持通过配置或代码逻辑定义复杂告警，并内置告警生命周期智能管理逻辑。 | 低   | 部分支持 | 12-18 人天 |
| 实现基于 Namespace 的资源配额管理   | 如何在多租户环境中，限制不同租户的 CPU、内存、存储等资源使用。 | 支持在命名空间级别对计算和存储资源设置硬性配额与弹性限制。      | 低   | 不支持  | 5-8 人天   |
| 实现基于角色访问控制（RBAC）的细粒度权限管理 | 如何精细化地管理不同用户对灾备功能（如切换、配置）的操作权限。   | 提供基于角色的访问控制，实现对平台各项操作的权限管理。        | 低   | 不支持  | 8-12 人天  |

---

#### 能力-4: 网络与数据面能力

| 技术手段                    | 解决的问题                               | 达成的效果                                     | 优先级 | 支持情况 | 预计交付时间   |
| :---------------------- | :---------------------------------- | :---------------------------------------- | :--- | :--- | :------- |
| 构建站点间数据同步的协调与监控服务       | 如何在平台层面统一管理和监控底层存储、数据库等组件的跨站点数据同步。  | 平台负责协调和监控底层组件实现跨数据中心的数据同步。                | 低   | 支持   | 8-10 人天  |
| 支持基础设施层面的多网络平面配置        | 如何满足将管理流量、业务流量、存储流量等隔离在不同物理网络平面的需求。 | 支持为节点配置多网卡，并为不同网络平面（Bond, VLAN）设置独立的路由策略。 | 低   | 支持   | 5-8 人天   |
| 集成基于 APISIX 的企业级 API 网关 | 如何为平台暴露的 API 提供丰富的流量治理和安全防护能力。      | 内置认证、限流、熔断等核心插件，并通过 CRD 实现声明式管理与自动化部署。    | 低   | 支持   | 10-15 人天 |

---

# AIPAAS (已立项)

### 支撑价值

AIPAAS 的建设核心聚焦于提升平台的自动化运维能力、高可用性及智能化故障处理水平。其价值体现在：

* 解决 **平台升级流程繁琐、依赖人工操作且过程不透明** 的问题，或满足 **简化升级过程、降低人为错误风险** 的原始需求，最终达成 **提供可视化、一键式的自动化升级体验** 的效果。
* 解决 **平台关键组件存在单点故障风险，影响整体服务稳定性** 的问题，或满足 **生产环境下平台自身的高可用保障** 的原始需求，最终达成 **通过全组件集群化部署实现故障自动切换** 的效果。
* 解决 **关键中间件（如 Milvus, MinIO）异常时，依赖手工脚本处置、响应慢** 的问题，或满足 **提升系统自愈能力** 的原始需求，最终达成 **实现中间件与 Kubernetes 集群的智能故障联动处置** 的效果。

---

### 平台能力需求

#### 能力-1: 可视化一键升级引擎

| 技术手段                   | 解决的问题                             | 达成的效果                                | 优先级 | 支持情况 | 预计交付时间   |
| :--------------------- | :-------------------------------- | :----------------------------------- | :--- | :--- | :------- |
| 开发图形化升级控制台，集成前置检查与流程编排 | 传统命令行升级方式对操作人员要求高，易出错，且缺乏直观的进度反馈。 | 提供清晰的升级向导，自动进行前置健康检查，并支持一键触发与监控升级流程。 | 中   | 支持   | 15-20 人天 |

---

#### 能力-2: 生产级高可用框架

| 技术手段                  | 解决的问题                                    | 达成的效果                           | 优先级 | 支持情况 | 预计交付时间   |
| :-------------------- | :--------------------------------------- | :------------------------------ | :--- | :--- | :------- |
| 为所有关键组件提供多实例、高可用的部署方案 | AIPAAS 的部分关键组件若采用单 Master 部署，会成为系统的单点故障。 | 确保所有关键组件均为集群化部署，实现无单点故障和自动故障切换。 | 中   | 支持   | 10-15 人天 |

---

#### 能力-3: 智能故障联动处置

| 技术手段                        | 解决的问题                                      | 达成的效果                                     | 优先级 | 支持情况 | 预计交付时间   |
| :-------------------------- | :----------------------------------------- | :---------------------------------------- | :--- | :--- | :------- |
| 构建标准化框架，实现中间件状态监测与 K8s 协同处置 | Milvus、MinIO 等关键中间件异常时，需要人工介入执行一系列复杂的恢复操作。 | 当监测到中间件异常时，能自动触发 Pod 重建、节点隔离等协同处置，替代手工脚本。 | 中   | 不支持  | 20-25 人天 |

---

# AICP-2.4.0 (已立项)

### 支撑价值

平台建设旨在强化对异构 AI 算力的监控、提升 AI 服务的可观测性、优化运维体验，并解决交付、迁移和升级中的痛点。其价值体现在：

* 解决 **GPU 掉卡、温度过高等硬件故障无法及时发现** 的问题，或满足 **对 N 卡、国产卡等异构算力进行统一健康监控** 的原始需求，最终达成 **提供覆盖多品牌 GPU 的故障与性能监控告警能力** 的效果。
* 解决 **缺乏对 API Key 及 MaaS 服务消费用量的精细化度量与观测** 的问题，或满足 **业务方对模型服务成本核算与性能分析** 的原始需求，最终达成 **构建包含用量统计、性能监控的多维度 AI 服务可观测性中心** 的效果。
* 解决 **模型服务日志分散，查询与导出操作不便** 的问题，或满足 **快速定位线上问题、进行日志审计** 的原始需求，最终达成 **提供集中化、可便捷搜索与导出的模型服务日志中心** 的效果。
* 解决 **平台交付流程复杂，依赖现场环境配置** 的问题，或满足 **软硬件一体化、开箱即用的交付模式** 的原始需求，最终达成 **提供包含母盘镜像、OVA 等多种格式的标准化交付物** 的效果。
* 解决 **平台从虚拟机迁移至 HCI 架构时，业务中断、数据丢失风险高** 的问题，或满足 **业务无感、数据无损的平滑迁移** 的原始需求，最终达成 **提供跨平台在线无损迁移的能力** 的效果。
* 解决 **组件 Chart 版本与应用版本强绑定，导致频繁的无效变更** 的问题，或满足 **敏捷开发模式下对应用快速迭代、独立升级** 的原始需求，最终达成 **构建解耦的、面向 XaaS 化应用的敏捷升级引擎** 的效果。
* 解决 **SKE 升级流程因个别异常节点或集群而被阻塞，缺乏灵活性** 的问题，或满足 **在存在已知、可接受异常的情况下继续执行升级** 的原始需求，最终达成 **提供可跳过异常节点的智能、容错升级调度机制** 的效果。
* 解决 **操作系统内核、驱动等底层组件升级需要中断业务** 的问题，或满足 **AI 训练、推理等长时任务的极致可用性保障** 的原始需求，最终达成 **通过热升级技术实现业务无感知的系统底层维护** 的效果。

---

### 平台能力需求

#### 能力-1: 异构算力健康监控服务

| 技术手段                      | 解决的问题                            | 达成的效果                                | 优先级 | 支持情况 | 预计交付时间   |
| :------------------------ | :------------------------------- | :----------------------------------- | :--- | :--- | :------- |
| 集成 NVIDIA、国产卡等厂商的监控驱动与管理库 | 如何在单一平台中统一监控来自不同供应商的 GPU 硬件状态。   | 提供统一的 GPU 健康状态（如掉卡、温度）采集能力，屏蔽底层硬件差异。 | 高   | 部分支持 | 15-20 人天 |
| 预设针对 GPU 场景的智能告警规则        | 通用告警规则无法精准捕捉 GPU 的典型故障模式（如持续高温）。 | 内置针对 GPU 的智能告警策略，并通过平台告警中心实时通知运维人员。  | 高   | 部分支持 | 5-8 人天   |

---

#### 能力-2: AI 服务可观测性中心

| 技术手段                           | 解决的问题                              | 达成的效果                             | 优先级 | 支持情况 | 预计交付时间   |
| :----------------------------- | :--------------------------------- | :-------------------------------- | :--- | :--- | :------- |
| 构建面向 API Key、租户、模型的多维度实时用量统计服务 | 如何精细化地计量 AI 模型服务的资源消耗，用于成本分摊或用量分析。 | 提供实时的用量统计仪表盘与可导出的报表。              | 高   | 部分支持 | 10-15 人天 |
| 自动化采集并展示模型服务的关键性能指标（KPIs）      | 如何评估和监控模型服务自身的性能表现，如 QPS、延迟等。      | 自动采集并展示模型服务的 QPS、响应延迟、错误率等关键性能指标。 | 高   | 部分支持 | 8-12 人天  |
| 提供可扩展的监控框架与标准业务指标接入接口          | 业务产线希望在统一的观测平台中展示其自定义的业务特定指标。      | 允许业务产线便捷地接入并展示其自定义的业务指标。          | 高   | 部分支持 | 8-10 人天  |

---

#### 能力-3: 模型服务日志中心

| 技术手段                  | 解决的问题                            | 达成的效果                        | 优先级 | 支持情况 | 预计交付时间 |
| :-------------------- | :------------------------------- | :--------------------------- | :--- | :--- | :----- |
| 汇聚所有模型服务实例的标准输出与应用日志  | 模型服务日志分散在不同的 Pod 中，难以进行统一的管理和查询。 | 实现模型服务日志的集中化管理。              | 高   | 部分支持 | 5-8 人天 |
| 提供基于多维度条件的日志查询界面与导出功能 | 如何在海量日志中快速找到特定请求或特定时间范围内的相关日志。   | 提供便捷的日志查询界面，并支持将搜索结果一键导出为文件。 | 高   | 部分支持 | 5-8 人天 |

---

#### 能力-4: 交付、迁移与升级

| 技术手段                             | 解决的问题                                   | 达成的效果                                     | 优先级 | 支持情况 | 预计交付时间   |
| :------------------------------- | :-------------------------------------- | :---------------------------------------- | :--- | :--- | :------- |
| 构建一体化母盘镜像和标准 OVA 格式的安装包生成流水线     | 如何为不同交付场景（物理机、虚拟机）提供标准、便捷的交付方式。         | 实现硬件开箱即用（母盘）和主流虚拟化环境中的快速导入部署（OVA）。        | 高   | 支持   | 10-15 人天 |
| 开发支持在线迁移的工具集与方案                  | 如何在确保业务连续和数据无损的前提下，将平台从一个基础设施迁移到另一个。    | 提供工具和方案，支持将组件和业务数据在线迁移至 HCI 平台，服务不中断。     | 高   | 不支持  | 25-30 人天 |
| 实现 Chart 版本与应用镜像版本的解耦管理          | 每次应用代码更新都强制要求修改上层 Chart 版本，增加了不必要的运维工作。 | 允许应用更新时 Chart 版本保持稳定，减少频繁修改的运维开销。         | 高   | 部分支持 | 8-12 人天  |
| 重构升级框架以支持 XaaS 化应用的复杂升级逻辑        | 现有升级框架对需要进行数据迁移、复杂预检查的 XaaS 应用支持不足。     | 升级框架能够通过标准接口处理 XaaS 化应用的预检查、数据迁移、回滚等复杂逻辑。 | 高   | 部分支持 | 15-20 人天 |
| 在升级前置检查中提供“忽略异常并继续”的选项           | SKE 升级流程过于严格，单个非关键性异常就会阻塞整个升级过程。        | 对非关键性异常，提供“忽略并继续”的选项，允许管理员决策后继续升级。        | 高   | 不支持  | 5-8 人天   |
| 实现操作系统内核与驱动的热升级（Live Patching）能力 | 升级 OS 内核、驱动等底层组件必须重启服务器，导致业务中断。         | 支持操作系统内核、驱动等底层组件的热升级，无需重启节点或中断业务。         | 高   | 不支持  | 30-40 人天 |


---

好的，遵照您的要求，我们来补充“SAAS业务上平台”这一场景在可靠性与灰度能力方面的构建与增强。

---

# SA-SAAS业务通过平台上线

### 支撑价值

平台建设旨在为上层SaaS业务提供电信级的稳定性和敏捷的交付能力，确保业务在云原生环境下的高可用与发布安全。其价值体现在：

* 解决 **平台基础设施（如节点、机架）的单点故障可能导致SaaS业务中断** 的问题，或满足 **业务对高SLA（服务等级协议）的承诺、抵御常见基础设施故障** 的原始需求，最终达成 **应用实例的跨故障域高可用部署与故障自动恢复** 的效果。
* 解决 **新版本全量发布带来的“一发即全身”的风险，一次有缺陷的发布可能影响所有用户** 的问题，或满足 **在生产环境中对新功能进行小范围验证、平滑过渡** 的原始需求，最终达成 **基于流量切分的灰度发布（金丝雀发布），实现低风险、可观测、可回滚的敏捷交付** 的效果。

---

### 平台能力需求

#### 能力-1: 高可用与故障自愈

| 技术手段                                      | 解决的问题                                        | 达成的效果                                                | 优先级 | 支持情况 | 预计交付时间  |
| :---------------------------------------- | :------------------------------------------- | :--------------------------------------------------- | :-- | :--- | :------ |
| 提供标准化的多副本（Multi-Replica）部署与健康检查（Probes）模板 | 应用的单个实例（Pod）异常退出或无响应，导致部分服务能力丧失。             | 确保应用始终维持预期的健康副本数，通过自动化重启或隔离无响应实例，实现进程级的故障自愈。         | 高   | 支持   | 3-5 人天  |
| 配置跨节点/跨可用区的Pod反亲和性（Anti-Affinity）调度策略     | 同一应用的所有副本被调度到单一物理节点或机架上，形成单点故障。              | 将应用副本强制分散到不同的物理节点或可用区，极大提升应用抵御硬件及区域性故障的能力。           | 高   | 支持   | 5-8 人天  |
| 增强节点故障监控与Pod自动驱逐、重建机制                     | 当节点宕机或进入NotReady状态时，其上运行的Pod无法自动、快速地迁移至健康节点。 | 在分钟级内识别到失效节点，并自动将其上的业务Pod在其他健康节点上进行重建，缩短业务恢复时间（RTO）。 | 高   | 部分支持 | 8-12 人天 |

---

#### 能力-2: 灰度发布与流量治理

| 技术手段                                                  | 解决的问题                                      | 达成的效果                                                               | 优先级 | 支持情况 | 预计交付时间   |
| :---------------------------------------------------- | :----------------------------------------- | :------------------------------------------------------------------ | :-- | :--- | :------- |
| 基于Ingress Controller实现按权重（Weight-based）的流量切分          | 如何将一小部分（如10%）的生产流量导入到新版本，同时大部分流量仍由稳定版本处理。  | 允许用户通过简单的配置，按百分比将入口流量在不同版本的服务之间进行划分，实现金丝雀发布。                        | 高   | 部分支持 | 10-15 人天 |
| 基于服务网格（Service Mesh）或高级API网关实现按内容（Content-based）的流量路由 | 如何实现更精细的灰度策略，例如只让内部员工、特定用户或来自特定设备的用户访问新版本。 | 支持根据HTTP头（如User-Agent）、Cookie、Header等请求内容进行流量路由，实现更灵活的A/B测试和灰度发布场景。 | 高   | 不支持  | 20-30 人天 |
| 提供自动化的灰度发布流水线与可观测性视图                                  | 灰度发布过程依赖人工监控和手动调整流量比例，过程繁琐且易出错。            | 提供可视化的发布控制台，集成关键业务指标（如错误率、延迟）监控，实现基于指标的自动流量推进或回滚。                   | 高   | 不支持  | 25-35 人天 |


---


3）洞察&规划方向，及其投入与效果分析

3.1 虚拟集群方向：SAAS业务&内部野生k8s降本和隔离效果；

通过在宿主集群的一个命名空间内运行一个独立的、功能完整的 Kubernetes 控制平面，提供了近乎完整的 K8s API 功能。这实现了比命名空间更强的隔离性，同时避免了维护多个物理集群的巨大开销。

降本增效：vCluster的轻量级控制平面（通常基于k3s）大幅降低了CPU和内存占用，能够在同一组物理节点上运行更多的租户集群，降低基础设施成本。

平衡隔离与成本：在提供更强隔离（每个租户有自己的API Server、调度器等）的同时，避免了多物理集群的沉重负担，实现了成本与隔离性的良好平衡。

将那些分散的、未经统一管理的“野生”K8s集群（可能是不同版本、不同配置）逐步迁移到由的虚拟集群平台上，降低管理和运维成本高昂，提高了通用功能复用性。

3.2 平台+组件统一智能运维：出海要求、提升产品自助服务能力，以DFX为内部落点，产品简单增加服务和外挂数据就具备类似多语言的统一能力；


3.3 HA二主机（主从）轻量化：资源消耗、性价比、轻量化基础设施价值场景；资源消耗：

| 特性           | K3s HA (kine+k3s+PostgreSQL) | K8s+etcd              |
| -------------- | ----------------------------- | --------------------- |
| 最低内存需求   | 单节点 512MB                  | 单节点 2GB            |
| 推荐节点配置   | 2 核 CPU, 1GB 内存            | 4 核 CPU, 4GB 内存    |
| 存储占用       | 低 (~100MB 初始)              | 高 (~500MB 初始)      |
| 部署复杂度     | 简单, 单命令部署              | 复杂, 需多组件配置    |
| 运维难度       | 低, 简化的组件架构            | 高, 多组件协同管理    |
| 高可用配置     | 2 节点即可实现                 | 至少 3 节点           |
| 适用规模       | 中小规模 (<100 节点)          | 大规模 (>100 节点)    |
| 启动时间       | 秒级                          | 分钟级                |
| 网络开销       | 低                            | 高                    |
| 边缘环境适配   | 优秀                          | 一般                  |
| 总体拥有成本   | 低                            | 高                    |



# 业务价值场景：

以“低资源、低运维、低成本”为核心，让Kubernetes的能力从“大规模生产环境”下沉到“中小团队、边缘、测试”等场景，解决了小场景田不起k8c。用不好k8s”的痛点，是实现“容器化入门”和“轻量场景落地”的高性价比选择。

| 业务价值                           |
| ---------------------------------- |
| 满足“中小规模场景”的核心需求      |
| 弥补业务使用 Kubernetes 二节点场景空缺 |
| 简化部署，提升了部署的效率          |
| 中小团队、边缘、测试场景            |


3.4【长期，AI中台】智能体平台能力：从vm到pod，从pod到agent的平台管理能力（虚拟化到容器化，从容器化到AI应用），AI必备组件和框架，serverless模式对接业务

1. 实现卡级亚健康检测隔离处置框架，避免节点故障、设备故障导致业务性能底下以及业务中断；

预期效果：提升可靠性，避免因亚健康状态累积导致的雪崩式故障，将故障从被动发现转为主动预测和隔离，大幅降低业务中断次数和时长。提升运维效率，将运维人员从重复性的紧急故障处理中解放出来，专注于更高价值的架构优化和策略制定工作。自动化处置大幅减少人工干预；降低运维成本，减少因业务中断导致的损失。

2. 高性能分布式存储，保障数据可靠性以及业务可靠性

AI工作负载（尤其是训练和推理）是数据密集型和计算密集型的，传统的存储方案往往成为瓶颈，导致GPU等昂贵计算资源空闲等待，拉长训练周期，降低业务响应速度。同时，数据的可靠性直接关系到模型的准确性和业务的连续性。

预期效果：最大化gpu利用率，减少因io而导致的gpu空闲等待；同时进行数据可靠性保障，避免数据丢失或者单点故障而导致ai业务中断

4) 总结

4.1 融合平台自身能力演进的部分汇总
4.2 洞察规划对外可赋能的部分汇总  
4.3 面向产线和业务趋势的部分汇总